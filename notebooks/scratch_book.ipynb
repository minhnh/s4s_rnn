{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sweat4science.workspace.Workspace import Workspace\n",
    "from sweat4science.evaluation.sessionset import MF_sessionset as mfs\n",
    "import sweat4science as s4s\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from s4s_rnn import utils\n",
    "\n",
    "# import sys\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workspace_folder = \"/home/minh/workspace/git/rnd/session-data\"\n",
    "ws = Workspace(workspace_folder)\n",
    "sessions = mfs.ICT_indoor(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for session in sessions:\n",
    "    if len(re.findall(\"slope\", str(session))) > 0:\n",
    "        sessions.remove(session)\n",
    "    pass\n",
    "\n",
    "sessions = np.array(sessions)\n",
    "print(\"\\n\".join(map(str, sessions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "s = sessions[0]\n",
    "data = np.array([s.distance, s.velocity, s.acceleration, s.time, s.hbm], ndmin=2).T\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_scaled = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(x_scaled[:20])\n",
    "scaler.inverse_transform(x_scaled)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(sessions, result_dir, experiment_name, date_string,\n",
    "                              time_steps, hidden_neurons, num_epoch, input_dim=4,\n",
    "                              save_plot=False, time_horizon=None):\n",
    "    # Construct base name\n",
    "    base_name = \"%s_%s_%02dstep_%02din_%03dhidden_%03depoch_\" \\\n",
    "                % (experiment_name, date_string, time_steps, input_dim, hidden_neurons, num_epoch)\n",
    "#     base_name = experiment_name + \"_\" + str(time_steps) + \"step_\" + str(input_dim) + \"in_\" \\\n",
    "#         + str(hidden_neurons) + \"hidden_\" + date_string + \"_\" + str(num_epoch) + \"epoch_\"\n",
    "    base_name = os.path.join(result_dir, base_name)\n",
    "    print(\"\\nBase name: %s\\n\" % (base_name))\n",
    "\n",
    "    # Open model\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    # Cross validation testing\n",
    "    test_predictions = None\n",
    "    test_actual_outputs = None\n",
    "    kf = KFold(len(sessions))\n",
    "    for train_index, test_index in kf.split(sessions):\n",
    "        test_sessions = sessions[test_index]\n",
    "        print(\"\\nTesting on:\\n\" + \"\\n\".join(map(str, test_sessions)))\n",
    "\n",
    "        test_data_x, test_data_y, scaler = \\\n",
    "            utils.get_data_from_sessions(test_sessions, time_steps, return_norm=True)\n",
    "\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        match = re.match('.+/running_indoor_(.+)/(\\d+)>', str(test_sessions[0]))\n",
    "        cross_validation_name = base_name + match.groups()[0] + \"_\" + match.groups()[1] + \"_\"\n",
    "\n",
    "        test_data_y_unnormed, test_predict_unnormed, mse = \\\n",
    "            utils.evaluate_model(loaded_model, cross_validation_name + \"weights.h5\",\n",
    "                                 test_data_x, test_data_y, scaler, horizon=time_horizon)\n",
    "\n",
    "        print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, np.sqrt(mse)))\n",
    "\n",
    "        if time_horizon is None:\n",
    "            plot_title = \"Heart rate simulation for running_indoor_\"\n",
    "            pass\n",
    "        else:\n",
    "            plot_title = \"Heart rate prediction at %ds horizon for running_indoor_\" % time_horizon\n",
    "            pass\n",
    "\n",
    "        plot_title += match.groups()[0] + \"/\" + match.groups()[1] + \", lookback of \" + str(time_steps)\n",
    "        utils.plot_predictions(test_predict_unnormed, test_data_y_unnormed, cross_validation_name + \"result.png\",\n",
    "                               plot_title)\n",
    "\n",
    "        test_predictions = test_predict_unnormed if test_predictions is None \\\n",
    "            else np.append(test_predictions, test_predict_unnormed, axis=0)\n",
    "        test_actual_outputs = test_data_y_unnormed if test_actual_outputs is None \\\n",
    "            else np.append(test_actual_outputs, test_data_y_unnormed, axis=0)\n",
    "\n",
    "        pass\n",
    "\n",
    "    mse = np.mean((test_predictions - test_actual_outputs)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"\\nOverall results:\\n MSE: %.5f\\n RMSE: %.5f\" % (mse, rmse))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161114\", time_steps=5, hidden_neurons=400, num_epoch=150, time_horizon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161114\", time_steps=10, hidden_neurons=400, num_epoch=150, time_horizon=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161114\", time_steps=15, hidden_neurons=400, num_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor_sigmoid\",\n",
    "                          date_string=\"20161127\", time_steps=10, hidden_neurons=400, num_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"artificial_data/sinx_plus_x.csv\", delimiter=',')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Artificially generated data\")\n",
    "plt.plot(data[:, -1:], 'g*')\n",
    "plt.show()\n",
    "\n",
    "data_mean = np.mean(data, axis=0)\n",
    "data_std = np.std(data, axis=0)\n",
    "data = (data - data_mean) / data_std\n",
    "\n",
    "num_train = int(0.9*len(data))\n",
    "test_data_x_ = data[num_train:, :-1]\n",
    "test_data_y = data[num_train:, -1:]\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "hidden_neurons = 400\n",
    "num_epoch = 50\n",
    "for ntsteps in [5, 10, 15]:\n",
    "    base_name = \"lstm_sinx_plus_x_\" + str(ntsteps) + \"step_\" + str(input_dim) +\\\n",
    "                \"in_\" + str(hidden_neurons) + \"hidden_\" + \"20161116\" +\\\n",
    "                \"_\" + str(num_epoch) + \"epoch_\"\n",
    "    base_name = os.path.join(\"train_results\", base_name)\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    test_data_x = utils.reshape_array_by_time_steps(test_data_x_, time_steps=ntsteps)\n",
    "    \n",
    "    test_data_y_unnormed, test_predict_unnormed, mse = \\\n",
    "            utils.evaluate_model(loaded_model, base_name + \"weights.h5\",\n",
    "                                 test_data_x, test_data_y, data_mean[-1], data_std[-1])\n",
    "\n",
    "    print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, np.sqrt(mse)) )\n",
    "\n",
    "    # Plot\n",
    "    utils.plot_predictions(test_predict_unnormed, test_data_y_unnormed, base_name + \"result.png\",\n",
    "                           \"Artificial data of function sin(x) + x, lookback of \" + str(ntsteps), y_label=\"Output\")\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
