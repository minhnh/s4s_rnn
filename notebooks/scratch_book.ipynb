{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sweat4science.workspace.Workspace import Workspace\n",
    "from sweat4science.evaluation.sessionset import MF_sessionset as mfs\n",
    "import sweat4science as s4s\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from s4s_rnn import utils, evaluation\n",
    "\n",
    "# import sys\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workspace_folder = \"/home/minh/workspace/git/rnd/session-data\"\n",
    "ws = Workspace(workspace_folder)\n",
    "sessions = mfs.ICT_indoor(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for session in sessions:\n",
    "    if len(re.findall(\"slope\", str(session))) > 0:\n",
    "        sessions.remove(session)\n",
    "    pass\n",
    "\n",
    "sessions = np.array(sessions)\n",
    "print(\"\\n\".join(map(str, sessions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(sessions, result_dir, model_name, experiment_name, date_string,\n",
    "                              time_steps, hidden_neurons, num_epoch, input_dim=4,\n",
    "                              save_plot=False, time_horizon=None, old_norm=False,\n",
    "                              plot_input=False):\n",
    "    predictions = {}\n",
    "    # Construct base name\n",
    "    base_name = \"%s_%s_%s_%02dstep_%02din_%03dhidden_%03depoch_\" \\\n",
    "                % (model_name, experiment_name, date_string, time_steps, input_dim, hidden_neurons, num_epoch)\n",
    "#     base_name = experiment_name + \"_\" + str(time_steps) + \"step_\" + str(input_dim) + \"in_\" \\\n",
    "#         + str(hidden_neurons) + \"hidden_\" + date_string + \"_\" + str(num_epoch) + \"epoch_\"\n",
    "    base_name = os.path.join(result_dir, base_name)\n",
    "    print(\"\\nBase name: %s\\n\" % (base_name))\n",
    "\n",
    "    # Open model\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    # Cross validation testing\n",
    "    test_predictions = None\n",
    "    test_actual_outputs = None\n",
    "    kf = KFold(len(sessions))\n",
    "    for train_index, test_index in kf.split(sessions):\n",
    "        test_sessions = sessions[test_index]\n",
    "        print(\"\\nTesting on:\\n\" + \"\\n\".join(map(str, test_sessions)))\n",
    "\n",
    "        test_data_x, test_data_y, scaler = \\\n",
    "            utils.get_data_from_sessions(test_sessions, time_steps, return_norm=True, old_norm=old_norm)\n",
    "\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        match = re.match('.+/running_indoor_(.+)/(\\d+)>', str(test_sessions[0]))\n",
    "        cross_validation_name = base_name + match.groups()[0] + \"_\" + match.groups()[1] + \"_\"\n",
    "        session_name = \"%s_%s\" % (match.groups()[0], match.groups()[1])\n",
    "        prediction_name = \"%2dlookback_%dneurons\" % (time_steps, hidden_neurons)\n",
    "        if time_horizon is not None:\n",
    "            prediction_name += \"%dhorizon\" % time_horizon\n",
    "            pass\n",
    "\n",
    "        experiment_result = evaluation.ExperimentEvalutation(exp_name=session_name, scaler=scaler,\n",
    "                                                             true_output=test_data_y)\n",
    "\n",
    "        prediction = utils.evaluate_model(loaded_model, cross_validation_name + \"weights.h5\",\n",
    "                                          test_data_x, test_data_y, horizon=time_horizon)\n",
    "        experiment_result.add_prediction(prediction_name, prediction, unnormalize=True)\n",
    "\n",
    "        print(\"MSE: %.5f\\nRMSE: %.5f\" % (experiment_result.mse[prediction_name],\n",
    "                                         np.sqrt(experiment_result.mse[prediction_name])))\n",
    "\n",
    "        if time_horizon is None:\n",
    "            plot_title = \"Heart rate simulation for running_indoor_\"\n",
    "        else:\n",
    "            plot_title = \"Heart rate prediction at %ds horizon for running_indoor_\" % time_horizon\n",
    "            pass\n",
    "\n",
    "        plot_title += match.groups()[0] + \"/\" + match.groups()[1] + \", lookback of \" + str(time_steps)\n",
    "        utils.plot_predictions(experiment_result.predictions[prediction_name],\n",
    "                               experiment_result.true_output[-len(prediction):],\n",
    "                               cross_validation_name + \"result.png\", plot_title)\n",
    "\n",
    "        if plot_input:\n",
    "            utils.plot_inputs(test_data_x[:, -1, :])\n",
    "            pass\n",
    "\n",
    "        test_predictions = experiment_result.predictions[prediction_name] if test_predictions is None \\\n",
    "            else np.append(test_predictions, experiment_result.predictions[prediction_name], axis=0)\n",
    "        test_actual_outputs = experiment_result.true_output if test_actual_outputs is None \\\n",
    "            else np.append(test_actual_outputs, experiment_result.true_output, axis=0)\n",
    "\n",
    "        predictions[session_name] = experiment_result\n",
    "\n",
    "        pass\n",
    "\n",
    "    mse = np.mean((test_predictions - test_actual_outputs)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"\\nOverall results:\\n MSE: %.5f\\n RMSE: %.5f\" % (mse, rmse))\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", model_name=\"lstm\", experiment_name=\"indoor\",\n",
    "                          date_string=\"20161205\", time_steps=5, hidden_neurons=400, num_epoch=150, time_horizon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", model_name=\"gru\", experiment_name=\"indoor\",\n",
    "                          date_string=\"20161208\", time_steps=5, hidden_neurons=400, num_epoch=150, time_horizon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", model_name=\"lstm\", experiment_name=\"indoor\",\n",
    "                          date_string=\"20161114\", time_steps=5, hidden_neurons=400, num_epoch=150, time_horizon=None,\n",
    "                          old_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161205\", time_steps=10, hidden_neurons=400, num_epoch=150, time_horizon=None,\n",
    "                          old_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "#                           date_string=\"20161114\", time_steps=10, hidden_neurons=400, num_epoch=150, time_horizon=None,\n",
    "#                           old_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161205\", time_steps=15, hidden_neurons=400, num_epoch=150, time_horizon=None,\n",
    "                          old_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", model_name=\"lstm\", experiment_name=\"indoor\",\n",
    "                          date_string=\"20161205\", time_steps=10, hidden_neurons=400, num_epoch=150, time_horizon=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161205\", time_steps=10, hidden_neurons=400, num_epoch=150, old_norm=False,\n",
    "                          plot_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor\",\n",
    "                          date_string=\"20161114\", time_steps=10, hidden_neurons=400, num_epoch=150, old_norm=True,\n",
    "                          plot_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, result_dir=\"../train_results\", experiment_name=\"lstm_indoor_sigmoid\",\n",
    "                          date_string=\"20161127\", time_steps=10, hidden_neurons=400, num_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"artificial_data/sinx_plus_x.csv\", delimiter=',')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Artificially generated data\")\n",
    "plt.plot(data[:, -1:], 'g*')\n",
    "plt.show()\n",
    "\n",
    "data_mean = np.mean(data, axis=0)\n",
    "data_std = np.std(data, axis=0)\n",
    "data = (data - data_mean) / data_std\n",
    "\n",
    "num_train = int(0.9*len(data))\n",
    "test_data_x_ = data[num_train:, :-1]\n",
    "test_data_y = data[num_train:, -1:]\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "hidden_neurons = 400\n",
    "num_epoch = 50\n",
    "for ntsteps in [5, 10, 15]:\n",
    "    base_name = \"lstm_sinx_plus_x_\" + str(ntsteps) + \"step_\" + str(input_dim) +\\\n",
    "                \"in_\" + str(hidden_neurons) + \"hidden_\" + \"20161116\" +\\\n",
    "                \"_\" + str(num_epoch) + \"epoch_\"\n",
    "    base_name = os.path.join(\"train_results\", base_name)\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    test_data_x = utils.reshape_array_by_time_steps(test_data_x_, time_steps=ntsteps)\n",
    "    \n",
    "    test_data_y_unnormed, test_predict_unnormed, mse = \\\n",
    "            utils.evaluate_model(loaded_model, base_name + \"weights.h5\",\n",
    "                                 test_data_x, test_data_y, data_mean[-1], data_std[-1])\n",
    "\n",
    "    print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, np.sqrt(mse)) )\n",
    "\n",
    "    # Plot\n",
    "    utils.plot_predictions(test_predict_unnormed, test_data_y_unnormed, base_name + \"result.png\",\n",
    "                           \"Artificial data of function sin(x) + x, lookback of \" + str(ntsteps), y_label=\"Output\")\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
