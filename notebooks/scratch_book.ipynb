{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sweat4science.workspace.Workspace import Workspace\n",
    "from sweat4science.evaluation.sessionset import MF_sessionset as mfs\n",
    "import sweat4science as s4s\n",
    "\n",
    "from s4s_rnn import utils, evaluation\n",
    "\n",
    "# import sys\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workspace_folder = \"/home/minh/workspace/git/rnd/session-data\"\n",
    "ws = Workspace(workspace_folder)\n",
    "sessions = mfs.ICT_indoor(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for session in sessions:\n",
    "    if len(re.findall(\"slope\", str(session))) > 0:\n",
    "        sessions.remove(session)\n",
    "    pass\n",
    "\n",
    "sessions = np.array(sessions)\n",
    "print(\"\\n\".join(map(str, sessions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_dict = evaluation.ExperimentEvalutationDict(sessions)\n",
    "#glob.glob(\"../train_results/gru*05step*.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_path in glob.glob(\"../train_results/*.json\"):\n",
    "    match = re.match('.+20161114.+', model_path)\n",
    "    old_norm = False\n",
    "    if match is not None:\n",
    "        old_norm = True\n",
    "        pass\n",
    "    eval_dict.add_model_json(model_path, old_norm=old_norm)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for weight_path in glob.glob(\"../train_results/*.h5\"):\n",
    "    match = re.match('.+20161114.+', weight_path)\n",
    "    old_norm = False\n",
    "    if match is not None:\n",
    "        old_norm = True\n",
    "        pass\n",
    "    eval_dict.add_weight_file(weight_path, old_norm=old_norm)\n",
    "    pass\n",
    "\n",
    "# os.path.exists('../train_results/lstm_indoor_20161205_15step_04in_400hidden_150epoch_session_01_20150219_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(eval_dict.model_json.keys()))\n",
    "print()\n",
    "eval_dict.evaluate([#'lstm_lookback10_400neurons_oldnorm',\n",
    "                    #'lstm_lookback05_400neurons_oldnorm',\n",
    "                    'lstm_lookback10_400neurons',\n",
    "                    'lstm_lookback05_400neurons',\n",
    "                    'lstm_lookback15_400neurons',\n",
    "                    'gru_lookback05_400neurons',\n",
    "                    'gru_lookback10_400neurons',\n",
    "                    'gru_lookback15_400neurons'\n",
    "                    ])\n",
    "#['lstm_lookback10_400neurons_oldnorm', 'lstm_lookback05_400neurons_oldnorm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_dict['session_01_20150304'].plot_predictions([#'lstm_lookback05_400neurons_oldnorm',\n",
    "                                                   'lstm_lookback15_400neurons',\n",
    "                                                   #'gru_lookback05_400neurons',\n",
    "                                                   'gru_lookback15_400neurons'\n",
    "                                                   ],\n",
    "                                                  'lstm_lookback05_400neurons_oldnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_dict.plot_error_bar_predictions(\"Some title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.boxplot((eval_dict['session_01_20150304'].predictions['lstm_lookback05_400neurons_oldnorm']\n",
    "#              - eval_dict['session_01_20150304']._true_output), showmeans=True,\n",
    "#             labels=['lstm_lookback05_400neurons_oldnorm'])\n",
    "eval_dict.plot_error_box_predictions(prediction_keys=[#'lstm_lookback05_400neurons_oldnorm',\n",
    "                                                      #'lstm_lookback10_400neurons_oldnorm',\n",
    "                                                      'lstm_lookback05_400neurons',\n",
    "                                                      'gru_lookback05_400neurons',\n",
    "                                                      'lstm_lookback10_400neurons',\n",
    "                                                      'gru_lookback10_400neurons',\n",
    "                                                      'lstm_lookback15_400neurons',\n",
    "                                                      'gru_lookback15_400neurons'],\n",
    "                                     title=\"Box plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(sessions, evalutations, result_dir, model_name, experiment_name, date_string,\n",
    "                              time_steps, hidden_neurons, num_epoch, input_dim=4,\n",
    "                              save_plot=False, time_horizon=None, old_norm=False,\n",
    "                              plot_input=False):\n",
    "    if old_norm:\n",
    "        print(\"\\n---- Evaluating with old normalization technique:\")\n",
    "        pass\n",
    "    # Construct base name\n",
    "    base_name = \"%s_%s_%s_%02dstep_%02din_%03dhidden_%03depoch_\" \\\n",
    "                % (model_name, experiment_name, date_string, time_steps, input_dim, hidden_neurons, num_epoch)\n",
    "\n",
    "    base_name = os.path.join(result_dir, base_name)\n",
    "    print(\"\\nBase name: %s\\n\" % (base_name))\n",
    "\n",
    "    # Open model\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    # Cross validation testing\n",
    "    test_predictions = None\n",
    "    test_actual_outputs = None\n",
    "    kf = KFold(len(sessions))\n",
    "    for train_index, test_index in kf.split(sessions):\n",
    "        test_sessions = sessions[test_index]\n",
    "        print(\"\\nTesting on:\\n\" + \"\\n\".join(map(str, test_sessions)))\n",
    "\n",
    "        test_data_x, test_data_y = \\\n",
    "            utils.get_data_from_sessions(test_sessions, time_steps, return_norm=False, old_norm=old_norm)\n",
    "\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        match = re.match('.+/running_indoor_(.+)/(\\d+)>', str(test_sessions[0]))\n",
    "        cross_validation_name = base_name + match.groups()[0] + \"_\" + match.groups()[1] + \"_\"\n",
    "        session_name = \"%s_%s\" % (match.groups()[0], match.groups()[1])\n",
    "\n",
    "        if session_name not in evalutations:\n",
    "            evalutations[session_name] = evaluation.ExperimentEvalutation(session=test_sessions[0])\n",
    "            pass\n",
    "\n",
    "        prediction_name = \"%s_lookback%02d_%dneurons\" % (model_name, time_steps, hidden_neurons)\n",
    "        if old_norm:\n",
    "            prediction_name += \"_oldnorm\"\n",
    "            pass\n",
    "\n",
    "        if time_horizon is not None:\n",
    "            prediction_name += \"_%dhorizon\" % time_horizon\n",
    "            pass\n",
    "\n",
    "        prediction = utils.evaluate_model(loaded_model, cross_validation_name + \"weights.h5\",\n",
    "                                          test_data_x, test_data_y, horizon=time_horizon)\n",
    "        evalutations[session_name].add_prediction(prediction_name, prediction, unnormalize=True, old_norm=old_norm)\n",
    "\n",
    "        print(\"MSE: %.5f\\nRMSE: %.5f\" % (evalutations[session_name].mse[prediction_name],\n",
    "                                         np.sqrt(evalutations[session_name].mse[prediction_name])))\n",
    "\n",
    "        prediction = evalutations[session_name].predictions[prediction_name]\n",
    "        test_predictions = prediction if test_predictions is None \\\n",
    "            else np.append(test_predictions, prediction, axis=0)\n",
    "        true_output = evalutations[session_name].true_output[-len(prediction):]\n",
    "        test_actual_outputs = true_output if test_actual_outputs is None \\\n",
    "            else np.append(test_actual_outputs, true_output, axis=0)\n",
    "\n",
    "        pass\n",
    "\n",
    "    mse = np.mean((test_predictions - test_actual_outputs)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"\\nOverall results:\\n MSE: %.5f\\n RMSE: %.5f\" % (mse, rmse))\n",
    "\n",
    "    return #evalutations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "evaluate_cross_validation(sessions=sessions, evalutations=eval_dict, result_dir=\"../train_results\", model_name=\"lstm\",\n",
    "                          experiment_name=\"indoor\", date_string=\"20161205\", time_steps=5, hidden_neurons=400,\n",
    "                          num_epoch=150, time_horizon=None)\n",
    "# evaluate_cross_validation(sessions=sessions, evalutations=eval_dict, result_dir=\"../train_results\", model_name=\"lstm\",\n",
    "#                           experiment_name=\"indoor\", date_string=\"20161205\", time_steps=10, hidden_neurons=400,\n",
    "#                           num_epoch=150, time_horizon=None)\n",
    "# evaluate_cross_validation(sessions=sessions, evalutations=eval_dict, result_dir=\"../train_results\", model_name=\"lstm\",\n",
    "#                           experiment_name=\"indoor\", date_string=\"20161205\", time_steps=15, hidden_neurons=400,\n",
    "#                           num_epoch=150, time_horizon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for exp_name, exp_val in eval_dict.items():\n",
    "    plot_title = \"Heart rate simulation for running_indoor_\"\n",
    "#     plot_title = \"Heart rate prediction at %ds horizon for running_indoor_\" % time_horizon\n",
    "\n",
    "    # list(map(a.get, ('1', '3')))\n",
    "    plot_title += exp_name\n",
    "    exp_val.plot_predictions(sorted(exp_val.predictions.keys()), plot_title)\n",
    "    # utils.plot_inputs(test_data_x[:, -1, :])\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_cross_validation(sessions=sessions, evalutations=eval_dict, result_dir=\"../train_results\", model_name=\"gru\",\n",
    "                          experiment_name=\"indoor\", date_string=\"20161209\", time_steps=5, hidden_neurons=400,\n",
    "                          num_epoch=150, time_horizon=30, old_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for exp_name, exp_val in eval_dict.items():\n",
    "    plot_title = \"Heart rate simulation for running_indoor_\"\n",
    "#     plot_title = \"Heart rate prediction at %ds horizon for running_indoor_\" % time_horizon\n",
    "\n",
    "    # list(map(a.get, ('1', '3')))\n",
    "    plot_title += exp_name\n",
    "    exp_val.plot_predictions(['lstm_lookback10_400neurons', 'lstm_lookback10_400neurons_oldnorm'], plot_title)\n",
    "#     exp_val.plot_predictions(['gru_lookback05_400neurons_30horizon'], plot_title)\n",
    "    # utils.plot_inputs(test_data_x[:, -1, :])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "evaluate_cross_validation(sessions=sessions, evalutations=eval_dict, result_dir=\"../train_results\", model_name=\"lstm\",\n",
    "                          experiment_name=\"indoor\", date_string=\"20161205\", time_steps=5, hidden_neurons=400,\n",
    "                          num_epoch=150, time_horizon=None)\n",
    "evaluate_cross_validation(sessions=sessions, evalutations=eval_dict, result_dir=\"../train_results\", model_name=\"gru\",\n",
    "                          experiment_name=\"indoor\", date_string=\"20161209\", time_steps=5, hidden_neurons=400,\n",
    "                          num_epoch=150, time_horizon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for exp_name, exp_val in eval_dict.items():\n",
    "    plot_title = \"Heart rate simulation for running_indoor_\"\n",
    "#     plot_title = \"Heart rate prediction at %ds horizon for running_indoor_\" % time_horizon\n",
    "\n",
    "    # list(map(a.get, ('1', '3')))\n",
    "    plot_title += exp_name\n",
    "    utils.plot_predictions(list(exp_val.predictions.values()), list(exp_val.predictions.keys()),\n",
    "                           exp_val.true_output, \"result.png\", plot_title)\n",
    "    # utils.plot_inputs(test_data_x[:, -1, :])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"artificial_data/sinx_plus_x.csv\", delimiter=',')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Artificially generated data\")\n",
    "plt.plot(data[:, -1:], 'g*')\n",
    "plt.show()\n",
    "\n",
    "data_mean = np.mean(data, axis=0)\n",
    "data_std = np.std(data, axis=0)\n",
    "data = (data - data_mean) / data_std\n",
    "\n",
    "num_train = int(0.9*len(data))\n",
    "test_data_x_ = data[num_train:, :-1]\n",
    "test_data_y = data[num_train:, -1:]\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "hidden_neurons = 400\n",
    "num_epoch = 50\n",
    "for ntsteps in [5, 10, 15]:\n",
    "    base_name = \"lstm_sinx_plus_x_\" + str(ntsteps) + \"step_\" + str(input_dim) +\\\n",
    "                \"in_\" + str(hidden_neurons) + \"hidden_\" + \"20161116\" +\\\n",
    "                \"_\" + str(num_epoch) + \"epoch_\"\n",
    "    base_name = os.path.join(\"train_results\", base_name)\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    test_data_x = utils.reshape_array_by_time_steps(test_data_x_, time_steps=ntsteps)\n",
    "    \n",
    "    test_data_y_unnormed, test_predict_unnormed, mse = \\\n",
    "            utils.evaluate_model(loaded_model, base_name + \"weights.h5\",\n",
    "                                 test_data_x, test_data_y, data_mean[-1], data_std[-1])\n",
    "\n",
    "    print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, np.sqrt(mse)) )\n",
    "\n",
    "    # Plot\n",
    "    utils.plot_predictions(test_predict_unnormed, test_data_y_unnormed, base_name + \"result.png\",\n",
    "                           \"Artificial data of function sin(x) + x, lookback of \" + str(ntsteps), y_label=\"Output\")\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
