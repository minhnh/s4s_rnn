{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sweat4science.workspace.Workspace import Workspace\n",
    "from sweat4science.evaluation.sessionset import MF_sessionset as mfs\n",
    "import sweat4science as s4s\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from s4s_rnn import utils\n",
    "\n",
    "# import sys\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workspace_folder = \"/home/minh/workspace/git/rnd/session-data\"\n",
    "ws = Workspace(workspace_folder)\n",
    "# user_name=\"MF83\"\n",
    "# experiment_name = [\"running_indoor_lactate_test\", \"running_indoor_session_01\", \"running_indoor_session_03$\"]\n",
    "# session_number = None\n",
    "# sessions = ws.get(user_name, experiment_name, session_number)\n",
    "# sessions = sessions[0:3]\n",
    "\n",
    "sessions = mfs.ICT_indoor(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for session in sessions:\n",
    "    if len(re.findall(\"slope\", str(session))) > 0:\n",
    "        sessions.remove(session)\n",
    "    pass\n",
    "\n",
    "sessions = np.array(sessions)\n",
    "print(\"\\n\".join(map(str, sessions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct meaningful base name\n",
    "ntsteps = 5\n",
    "input_dim = 4\n",
    "output_dim = 1\n",
    "hidden_neurons = 400\n",
    "num_epoch = 200\n",
    "base_name = \"lstm_indoor_\" + str(ntsteps) + \"step_\" + str(input_dim) + \"in_\" + str(hidden_neurons) + \"hidden_\"\\\n",
    "            + \"20161112\" + \"_\" + str(num_epoch) + \"epoch_\"\n",
    "base_name = os.path.join(\"train_results\", base_name)\n",
    "print(base_name)\n",
    "\n",
    "model_file_name = base_name  + \"model.json\"\n",
    "json_file = open(model_file_name, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# Cross validation training\n",
    "test_predictions = None\n",
    "test_actual_outputs = None\n",
    "kf = KFold(len(sessions))\n",
    "for train_index, test_index in kf.split(sessions):\n",
    "    test_sessions = sessions[test_index]\n",
    "    print(\"\\nTesting on:\\n\" + \"\\n\".join(map(str, test_sessions)))\n",
    "\n",
    "    test_data_x, test_data_y = utils.get_data_from_sessions(test_sessions)\n",
    "    test_data_x = utils.reshape_array_by_time_steps(test_data_x, time_steps=ntsteps)\n",
    "    test_data_y = test_data_y[-len(test_data_x):]\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    match = re.match('.+/running_indoor_(.+)/(\\d+)>', str(test_sessions[0]))\n",
    "    cross_validation_name = base_name + match.groups()[0] + \"_\" + match.groups()[1] + \"_\"\n",
    "    loaded_model.load_weights(cross_validation_name + \"weights.h5\")\n",
    "    loaded_model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mse'])\n",
    "\n",
    "    test_predict = loaded_model.predict(test_data_x)\n",
    "    mse = np.mean((test_predict - test_data_y)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, rmse) )\n",
    "\n",
    "    test_predictions = test_predict if test_predictions is None \\\n",
    "        else np.append(test_predictions, test_predict, axis=0)\n",
    "    test_actual_outputs = test_data_y if test_actual_outputs is None \\\n",
    "        else np.append(test_actual_outputs, test_data_y, axis=0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(test_predict, 'r+')\n",
    "    plt.plot(test_data_y, 'g*')\n",
    "    plt.show()\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(test_predictions.shape)\n",
    "# print(test_actual_outputs.shape)\n",
    "\n",
    "mse = np.mean((test_predictions - test_actual_outputs)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, rmse) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"artificial_data/sinx_plus_x.csv\", delimiter=',')\n",
    "num_train = int(0.8*len(data))\n",
    "train_data_x_ = data[:num_train, :-1]\n",
    "train_data_y_ = data[:num_train, -1:]\n",
    "test_data_x_ = data[num_train:, :-1]\n",
    "test_data_y_ = data[num_train:, -1:]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_data_y_, 'g*')\n",
    "plt.show()\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "hidden_neurons = 400\n",
    "num_epoch = 20\n",
    "for ntsteps in [5, 10, 15]:\n",
    "    base_name = \"lstm_sinx_plus_x_\" + str(ntsteps) + \"step_\" + str(input_dim) +\\\n",
    "                \"in_\" + str(hidden_neurons) + \"hidden_\" + \"20161108\" +\\\n",
    "                \"_\" + str(num_epoch) + \"epoch_\"\n",
    "    base_name = os.path.join(\"train_results\", base_name)\n",
    "    model_file_name = base_name  + \"model.json\"\n",
    "    json_file = open(model_file_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    test_data_x = utils.reshape_array_by_time_steps(test_data_x_, time_steps=ntsteps)\n",
    "    test_data_y = test_data_y_[-len(test_data_x):]\n",
    "\n",
    "    loaded_model.load_weights(base_name + \"weights.h5\")\n",
    "    loaded_model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mse'])\n",
    "\n",
    "    test_predict = loaded_model.predict(test_data_x)\n",
    "    mse = np.mean((test_predict - test_data_y)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(\"MSE: %.5f\\nRMSE: %.5f\" % (mse, rmse) )\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(test_predict, 'r+')\n",
    "    plt.plot(test_data_y, 'g*')\n",
    "    plt.show()\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
